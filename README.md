# PySpark Data Quality Validator

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.5.0-orange)](https://spark.apache.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Projekt demonstrujcy walidacj jakoci danych w PySpark - od podstawowych funkcji pandas do zaawansowanych pipeline'贸w big data.

##  Cel projektu

Nauka:
- Przepisywania funkcji pandas na PySpark
- Testowania pipeline'贸w danych
- Optymalizacji wydajnoci big data
- Implementacji CI/CD dla jakoci danych

## Struktura projektu

```
pyspark-data-validator/
 requirements.txt          # Zale偶noci
 pyspark_validator.py      # G贸wna klasa walidatora
 example_usage.py          # Podstawowe przykady u偶ycia
 advanced_examples.py      # Zaawansowane scenariusze
 test_pyspark_validator.py # Testy jednostkowe
 README.md                # Ten plik
```

## Instalacja

```bash
pip install -r requirements.txt
```

## Uruchomienie

### Podstawowe przykady
```bash
python example_usage.py
```

### Zaawansowane funkcje
```bash
python advanced_examples.py
```

### Testy
```bash
pytest test_pyspark_validator.py -v
```

## Kluczowe funkcjonalnoci

### 1. Walidacja jakoci danych
- Sprawdzanie duplikat贸w
- Wykrywanie brakujcych wartoci
- Walidacja format贸w (email, telefon)
- Sprawdzanie ujemnych wartoci
- Zgodno schematu

### 2. Zaawansowane funkcje
- Pipeline walidacji jakoci
- Wykrywanie anomalii (IQR)
- ledzenie pochodzenia danych
- Analiza w oknach przesuwnych
- Strategie pr贸bkowania

### 3. Optymalizacja wydajnoci
- Partycjonowanie danych
- Cache'owanie DataFrame
- Monitorowanie wykonania

## Przykad u偶ycia

```python
from pyspark_validator import PySparkDataValidator

# Inicjalizacja
validator = PySparkDataValidator()

# Sprawdzenie duplikat贸w
result = validator.check_duplicates(df, columns=["id"])
print(f"Duplikaty: {result['duplicate_count']}")

# Walidacja emaili
email_result = validator.validate_email_column(df, "email")
print(f"Poprawne emaile: {email_result['validation_rate']}%")

# Zamknicie
validator.close()
```

## Scenariusze testowe dla rozmowy

1. **Big Data Processing**: Jak obsu偶y DataFrame z milionami rekord贸w?
2. **Performance Tuning**: Optymalizacja zapyta i partycjonowania
3. **Data Quality Pipelines**: Automatyzacja walidacji w CI/CD
4. **Schema Evolution**: Obsuga zmian w schemacie danych
5. **Anomaly Detection**: Wykrywanie nietypowych wzorc贸w w danych

## Kluczowe r贸偶nice PySpark vs Pandas

| Aspekt | Pandas | PySpark |
|--------|--------|---------|
| Przetwarzanie | Single-machine | Distributed |
| Lazy Evaluation | Nie | Tak |
| Memory Management | In-memory | Disk + Memory |
| SQL Support | Ograniczone | Pene wsparcie |
| Scalability | Ograniczona | Nieograniczona |

##  Contributing

Chtnie przyjm pull requesty! Szczeg贸lnie mile widziane:
- Nowe funkcje walidacyjne
- Optymalizacje wydajnoci
- Dodatkowe testy
- Przykady integracji z Azure/AWS

##  Kontakt

Rafa Pieczka - [LinkedIn](https://linkedin.com/in/rafal-pieczka)

##  Licencja

Projekt jest dostpny na licencji MIT - zobacz [LICENSE](LICENSE) dla szczeg贸贸w.